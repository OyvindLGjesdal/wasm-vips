From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Kleis Auke Wolthuizen <github@kleisauke.nl>
Date: Wed, 3 Feb 2021 13:00:00 +0100
Subject: [PATCH 1/1] Experiment with SIMD intrinsics

Upstream-Status: Pending

diff --git a/libvips/include/vips/memory.h b/libvips/include/vips/memory.h
index 1111111..2222222 100644
--- a/libvips/include/vips/memory.h
+++ b/libvips/include/vips/memory.h
@@ -68,6 +68,7 @@ void *vips_malloc( VipsObject *object, size_t size );
 char *vips_strdup( VipsObject *object, const char *str );
 
 void vips_tracked_free( void *s );
+void *vips_tracked_aligned_alloc( size_t size, size_t align );
 void *vips_tracked_malloc( size_t size );
 size_t vips_tracked_get_mem( void );
 size_t vips_tracked_get_mem_highwater( void );
diff --git a/libvips/iofuncs/buffer.c b/libvips/iofuncs/buffer.c
index 1111111..2222222 100644
--- a/libvips/iofuncs/buffer.c
+++ b/libvips/iofuncs/buffer.c
@@ -467,6 +467,7 @@ buffer_move( VipsBuffer *buffer, VipsRect *area )
 {
 	VipsImage *im = buffer->im;
 	size_t new_bsize;
+	size_t align;
 
 	g_assert( buffer->ref_count == 1 );
 
@@ -477,11 +478,24 @@ buffer_move( VipsBuffer *buffer, VipsRect *area )
 
 	new_bsize = (size_t) VIPS_IMAGE_SIZEOF_PEL( im ) * 
 		area->width * area->height;
+
+	/* Need to pad buffer size to be aligned-up to
+	 * 32 bytes for SIMD reduce.
+	 */
+#if defined(__AVX2__) || defined(__SSE4_2__)
+	if( im->BandFmt == VIPS_FORMAT_UCHAR ) {
+		new_bsize = (new_bsize + 31) & ~0x1F;
+		align = 32;
+	}
+	else
+#endif
+		align = 16;
+
 	if( buffer->bsize < new_bsize ||
 		!buffer->buf ) {
 		buffer->bsize = new_bsize;
 		VIPS_FREEF( vips_tracked_free, buffer->buf );
-		if( !(buffer->buf = vips_tracked_malloc( buffer->bsize )) ) 
+		if( !(buffer->buf = vips_tracked_aligned_alloc( buffer->bsize, align )) ) 
 			return( -1 );
 	}
 
diff --git a/libvips/iofuncs/memory.c b/libvips/iofuncs/memory.c
index 1111111..2222222 100644
--- a/libvips/iofuncs/memory.c
+++ b/libvips/iofuncs/memory.c
@@ -228,10 +228,9 @@ vips_strdup( VipsObject *object, const char *str )
 void
 vips_tracked_free( void *s )
 {
-	/* Keep the size of the alloc in the previous 16 bytes. Ensures
-	 * alignment rules are kept.
+	/* Keep the size of the alloc below the aligned buffer.
 	 */
-	void *start = (void *) ((char *) s - 16);
+	void *start = ((void **) s)[-1];
 	size_t size = *((size_t *) start);
 
 	g_mutex_lock( vips_tracked_mutex );
@@ -273,10 +272,12 @@ vips_tracked_init( void )
 }
 
 /**
- * vips_tracked_malloc:
+ * vips_tracked_aligned_alloc:
  * @size: number of bytes to allocate
+ * @align: specifies the alignment
  *
- * Allocate an area of memory that will be tracked by vips_tracked_get_mem()
+ * Allocate an area of memory aligned on a boundary specified
+ * by @align that will be tracked by vips_tracked_get_mem()
  * and friends. 
  *
  * If allocation fails, vips_malloc() returns %NULL and 
@@ -284,22 +285,30 @@ vips_tracked_init( void )
  *
  * You must only free the memory returned with vips_tracked_free().
  *
- * See also: vips_tracked_free(), vips_malloc().
+ * See also: vips_tracked_malloc(), vips_tracked_free(), vips_malloc().
  *
  * Returns: (transfer full): a pointer to the allocated memory, or %NULL on error.
  */
 void *
-vips_tracked_malloc( size_t size )
+vips_tracked_aligned_alloc( size_t size, size_t align )
 {
-        void *buf;
+	void *ptr, *buf;
 
 	vips_tracked_init(); 
 
 	/* Need an extra sizeof(size_t) bytes to track 
-	 * size of this block. Ask for an extra 16 to make sure we don't break
-	 * alignment rules.
+	 * size of this block.
+	 */
+	size += sizeof(size_t);
+
+	/* Ensure that the buffer is aligned.
+	 */
+	size += align - 1;
+
+	/* And we need extra space for storing a pointer to
+	 * the 'real' buffer below the aligned buffer.
 	 */
-	size += 16;
+	size += sizeof(void *);
 
         if( !(buf = g_try_malloc0( size )) ) {
 #ifdef DEBUG
@@ -318,7 +327,9 @@ vips_tracked_malloc( size_t size )
 	g_mutex_lock( vips_tracked_mutex );
 
 	*((size_t *)buf) = size;
-	buf = (void *) ((char *)buf + 16);
+	ptr = (void *) (((guintptr) buf + sizeof(size_t) +
+		align - 1 + sizeof(void *)) & ~(guintptr) (align - 1));
+	((void**)ptr)[-1] = buf;
 
 	vips_tracked_mem += size;
 	if( vips_tracked_mem > vips_tracked_mem_highwater ) 
@@ -333,7 +344,29 @@ vips_tracked_malloc( size_t size )
 
 	VIPS_GATE_MALLOC( size ); 
 
-        return( buf );
+	return( ptr );
+}
+
+/**
+ * vips_tracked_malloc:
+ * @size: number of bytes to allocate
+ *
+ * Allocate an area of memory that will be tracked by vips_tracked_get_mem()
+ * and friends. 
+ *
+ * If allocation fails, vips_malloc() returns %NULL and 
+ * sets an error message.
+ *
+ * You must only free the memory returned with vips_tracked_free().
+ *
+ * See also: vips_tracked_free(), vips_malloc().
+ *
+ * Returns: (transfer full): a pointer to the allocated memory, or %NULL on error.
+ */
+void *
+vips_tracked_malloc( size_t size )
+{
+	return( vips_tracked_aligned_alloc( size, 16 ) );
 }
 
 /**
diff --git a/libvips/resample/Makefile.am b/libvips/resample/Makefile.am
index 1111111..2222222 100644
--- a/libvips/resample/Makefile.am
+++ b/libvips/resample/Makefile.am
@@ -11,6 +11,7 @@ libresample_la_SOURCES = \
 	shrinkh.c \
 	shrinkv.c \
 	reduce.c \
+	reduce_simd.c \
 	reduceh.cpp \
 	reducev.cpp \
 	interpolate.c \
diff --git a/libvips/resample/presample.h b/libvips/resample/presample.h
index 1111111..2222222 100644
--- a/libvips/resample/presample.h
+++ b/libvips/resample/presample.h
@@ -73,6 +73,9 @@ int vips_reduce_get_points( VipsKernel kernel, double shrink );
 void vips_reduce_make_mask( double *c, 
 	VipsKernel kernel, double shrink, double x );
 
+void vips_reduce_uchar_simd( VipsPel *pout, const VipsPel *pin,
+	const int n, const int ne, const int lskip, const short *restrict k );
+
 #ifdef __cplusplus
 }
 #endif /*__cplusplus*/
diff --git a/libvips/resample/reduce_simd.c b/libvips/resample/reduce_simd.c
new file mode 100644
index 00000000..1111111
--- /dev/null
+++ b/libvips/resample/reduce_simd.c
@@ -0,0 +1,304 @@
+/* From: ResampleSIMDVerticalConv.c (Pillow-SIMD)
+ *
+ * 15/01/21 kleisauke
+ * 	- initial implementation
+ * 01/02/21 kleisauke
+ * 	- uint -> uchar
+ */
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif /*HAVE_CONFIG_H*/
+#include <vips/intl.h>
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <math.h>
+
+/* Microsoft compiler doesn't limit intrinsics for an architecture.
+ * This macro is set only on x86 and means SSE2 and above including AVX2. 
+ */
+#if defined(_M_X64) || _M_IX86_FP == 2
+#define __SSE4_2__
+#endif
+
+#ifdef __SSE4_2__
+#include <emmintrin.h>
+#include <smmintrin.h>
+#endif
+
+#ifdef __AVX2__
+#include <immintrin.h>
+#endif
+
+#include <vips/vips.h>
+#include <vips/debug.h>
+#include <vips/internal.h>
+
+#include "presample.h"
+
+#ifdef __SSE4_2__
+static __m128i inline
+mm_cvtepu8_epi32(const void *ptr) {
+	return _mm_cvtepu8_epi32(_mm_cvtsi32_si128(*(int *) ptr));
+}
+#endif
+
+#if defined(__AVX2__) || defined(__SSE4_2__)
+void
+vips_reduce_uchar_simd( VipsPel *pout, const VipsPel *pin,
+	const int n, const int ne, const int lskip, const short *restrict k ) {
+	unsigned char* restrict out = (unsigned char *) pout;
+	const unsigned char* restrict in = (unsigned char *) pin;
+	const int l1 = lskip / sizeof( unsigned char );
+
+	int x;
+	int xx = 0;
+
+	__m128i initial = _mm_set1_epi32(1 << (VIPS_INTERPOLATE_SHIFT - 1));
+
+#ifdef __AVX2__
+
+	__m256i initial_256 = _mm256_set1_epi32(1 << (VIPS_INTERPOLATE_SHIFT - 1));
+
+	for( ; xx < ne - 7; xx += 8 ) {
+		__m256i sss0 = initial_256;
+		__m256i sss1 = initial_256;
+		__m256i sss2 = initial_256;
+		__m256i sss3 = initial_256;
+		x = 0;
+		for( ; x < n - 1; x += 2 ) {
+			__m256i source, source1, source2;
+			__m256i pix, mmk;
+
+			// Load two coefficients at once
+			mmk = _mm256_set1_epi32(*(int *) &k[x]);
+
+			source1 = _mm256_loadu_si256(  // top line
+				(__m256i *) &in[x * l1 + xx]);
+			source2 = _mm256_loadu_si256(  // bottom line
+				(__m256i *) &in[(x + 1) * l1 + xx]);
+
+			source = _mm256_unpacklo_epi8(source1, source2);
+			pix = _mm256_unpacklo_epi8(source, _mm256_setzero_si256());
+			sss0 = _mm256_add_epi32(sss0, _mm256_madd_epi16(pix, mmk));
+			pix = _mm256_unpackhi_epi8(source, _mm256_setzero_si256());
+			sss1 = _mm256_add_epi32(sss1, _mm256_madd_epi16(pix, mmk));
+
+			source = _mm256_unpackhi_epi8(source1, source2);
+			pix = _mm256_unpacklo_epi8(source, _mm256_setzero_si256());
+			sss2 = _mm256_add_epi32(sss2, _mm256_madd_epi16(pix, mmk));
+			pix = _mm256_unpackhi_epi8(source, _mm256_setzero_si256());
+			sss3 = _mm256_add_epi32(sss3, _mm256_madd_epi16(pix, mmk));
+		}
+		for( ; x < n; x += 1) {
+			__m256i source, source1, pix, mmk;
+			mmk = _mm256_set1_epi32(k[x]);
+
+			source1 = _mm256_loadu_si256(  // top line
+				(__m256i *) &in[x * l1 + xx]);
+
+			source = _mm256_unpacklo_epi8(source1, _mm256_setzero_si256());
+			pix = _mm256_unpacklo_epi8(source, _mm256_setzero_si256());
+			sss0 = _mm256_add_epi32(sss0, _mm256_madd_epi16(pix, mmk));
+			pix = _mm256_unpackhi_epi8(source, _mm256_setzero_si256());
+			sss1 = _mm256_add_epi32(sss1, _mm256_madd_epi16(pix, mmk));
+
+			source = _mm256_unpackhi_epi8(source1, _mm256_setzero_si256());
+			pix = _mm256_unpacklo_epi8(source, _mm256_setzero_si256());
+			sss2 = _mm256_add_epi32(sss2, _mm256_madd_epi16(pix, mmk));
+			pix = _mm256_unpackhi_epi8(source, _mm256_setzero_si256());
+			sss3 = _mm256_add_epi32(sss3, _mm256_madd_epi16(pix, mmk));
+		}
+		sss0 = _mm256_srai_epi32(sss0, VIPS_INTERPOLATE_SHIFT);
+		sss1 = _mm256_srai_epi32(sss1, VIPS_INTERPOLATE_SHIFT);
+		sss2 = _mm256_srai_epi32(sss2, VIPS_INTERPOLATE_SHIFT);
+		sss3 = _mm256_srai_epi32(sss3, VIPS_INTERPOLATE_SHIFT);
+
+		sss0 = _mm256_packs_epi32(sss0, sss1);
+		sss2 = _mm256_packs_epi32(sss2, sss3);
+		sss0 = _mm256_packus_epi16(sss0, sss2);
+		_mm256_storeu_si256((__m256i *) &out[xx], sss0);
+	}
+
+#else
+
+	for( ; xx < ne - 7; xx += 8 ) {
+		__m128i sss0 = initial;
+		__m128i sss1 = initial;
+		__m128i sss2 = initial;
+		__m128i sss3 = initial;
+		__m128i sss4 = initial;
+		__m128i sss5 = initial;
+		__m128i sss6 = initial;
+		__m128i sss7 = initial;
+		x = 0;
+		for( ; x < n - 1; x += 2 ) {
+			__m128i source, source1, source2;
+			__m128i pix, mmk;
+
+			// Load two coefficients at once
+			mmk = _mm_set1_epi32(*(int *) &k[x]);
+
+			source1 = _mm_loadu_si128(  // top line
+				(__m128i *) &in[x * l1 + xx]);
+			source2 = _mm_loadu_si128(  // bottom line
+				(__m128i *) &in[(x + 1) * l1 + xx]);
+
+			source = _mm_unpacklo_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss0 = _mm_add_epi32(sss0, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss1 = _mm_add_epi32(sss1, _mm_madd_epi16(pix, mmk));
+
+			source = _mm_unpackhi_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss2 = _mm_add_epi32(sss2, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss3 = _mm_add_epi32(sss3, _mm_madd_epi16(pix, mmk));
+
+			source1 = _mm_loadu_si128(  // top line
+				(__m128i *) &in[x * l1 + xx + 4]);
+			source2 = _mm_loadu_si128(  // bottom line
+				(__m128i *) &in[(x + 1) * l1 + xx + 4]);
+
+			source = _mm_unpacklo_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss4 = _mm_add_epi32(sss4, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss5 = _mm_add_epi32(sss5, _mm_madd_epi16(pix, mmk));
+
+			source = _mm_unpackhi_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss6 = _mm_add_epi32(sss6, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss7 = _mm_add_epi32(sss7, _mm_madd_epi16(pix, mmk));
+		}
+		for( ; x < n; x += 1 ) {
+			__m128i source, source1, pix, mmk;
+			mmk = _mm_set1_epi32(k[x]);
+
+			source1 = _mm_loadu_si128(  // top line
+				(__m128i *) &in[x * l1 + xx]);
+	
+			source = _mm_unpacklo_epi8(source1, _mm_setzero_si128());
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss0 = _mm_add_epi32(sss0, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss1 = _mm_add_epi32(sss1, _mm_madd_epi16(pix, mmk));
+
+			source = _mm_unpackhi_epi8(source1, _mm_setzero_si128());
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss2 = _mm_add_epi32(sss2, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss3 = _mm_add_epi32(sss3, _mm_madd_epi16(pix, mmk));
+
+			source1 = _mm_loadu_si128(  // top line
+				(__m128i *) &in[x * l1 + xx + 4]);
+
+			source = _mm_unpacklo_epi8(source1, _mm_setzero_si128());
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss4 = _mm_add_epi32(sss4, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss5 = _mm_add_epi32(sss5, _mm_madd_epi16(pix, mmk));
+
+			source = _mm_unpackhi_epi8(source1, _mm_setzero_si128());
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss6 = _mm_add_epi32(sss6, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss7 = _mm_add_epi32(sss7, _mm_madd_epi16(pix, mmk));
+		}
+		sss0 = _mm_srai_epi32(sss0, VIPS_INTERPOLATE_SHIFT);
+		sss1 = _mm_srai_epi32(sss1, VIPS_INTERPOLATE_SHIFT);
+		sss2 = _mm_srai_epi32(sss2, VIPS_INTERPOLATE_SHIFT);
+		sss3 = _mm_srai_epi32(sss3, VIPS_INTERPOLATE_SHIFT);
+		sss4 = _mm_srai_epi32(sss4, VIPS_INTERPOLATE_SHIFT);
+		sss5 = _mm_srai_epi32(sss5, VIPS_INTERPOLATE_SHIFT);
+		sss6 = _mm_srai_epi32(sss6, VIPS_INTERPOLATE_SHIFT);
+		sss7 = _mm_srai_epi32(sss7, VIPS_INTERPOLATE_SHIFT);
+
+		sss0 = _mm_packs_epi32(sss0, sss1);
+		sss2 = _mm_packs_epi32(sss2, sss3);
+		sss0 = _mm_packus_epi16(sss0, sss2);
+		_mm_storeu_si128((__m128i *) &out[xx], sss0);
+		sss4 = _mm_packs_epi32(sss4, sss5);
+		sss6 = _mm_packs_epi32(sss6, sss7);
+		sss4 = _mm_packus_epi16(sss4, sss6);
+		_mm_storeu_si128((__m128i *) &out[xx + 4], sss4);
+	}
+
+#endif
+
+	for( ; xx < ne - 1; xx += 2 ) {
+		__m128i sss0 = initial;  // left row
+		__m128i sss1 = initial;  // right row
+		x = 0;
+		for( ; x < n - 1; x += 2 ) {
+			__m128i source, source1, source2;
+			__m128i pix, mmk;
+
+			// Load two coefficients at once
+			mmk = _mm_set1_epi32(*(int *) &k[x]);
+
+			source1 = _mm_loadl_epi64(  // top line
+				(__m128i *) &in[x * l1 + xx]);
+			source2 = _mm_loadl_epi64(  // bottom line
+				(__m128i *) &in[(x + 1) * l1 + xx]);
+
+			source = _mm_unpacklo_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss0 = _mm_add_epi32(sss0, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss1 = _mm_add_epi32(sss1, _mm_madd_epi16(pix, mmk));
+		}
+		for( ; x < n; x += 1 ) {
+			__m128i source, source1, pix, mmk;
+			mmk = _mm_set1_epi32(k[x]);
+
+			source1 = _mm_loadl_epi64(  // top line
+				(__m128i *) &in[x * l1 + xx]);
+
+			source = _mm_unpacklo_epi8(source1, _mm_setzero_si128());
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss0 = _mm_add_epi32(sss0, _mm_madd_epi16(pix, mmk));
+			pix = _mm_unpackhi_epi8(source, _mm_setzero_si128());
+			sss1 = _mm_add_epi32(sss1, _mm_madd_epi16(pix, mmk));
+		}
+		sss0 = _mm_srai_epi32(sss0, VIPS_INTERPOLATE_SHIFT);
+		sss1 = _mm_srai_epi32(sss1, VIPS_INTERPOLATE_SHIFT);
+
+		sss0 = _mm_packs_epi32(sss0, sss1);
+		sss0 = _mm_packus_epi16(sss0, sss0);
+		_mm_storel_epi64((__m128i *) &out[xx], sss0);
+	}
+
+	for( ; xx < ne; xx++ ) {
+		__m128i sss = initial;
+		x = 0;
+		for( ; x < n - 1; x += 2 ) {
+			__m128i source, source1, source2;
+			__m128i pix, mmk;
+	
+			// Load two coefficients at once
+			mmk = _mm_set1_epi32(*(int *) &k[x]);
+
+			source1 = _mm_cvtsi32_si128(  // top line
+				*(int *) &in[x * l1 + xx]);
+			source2 = _mm_cvtsi32_si128(  // bottom line
+				*(int *) &in[(x + 1) * l1 + xx]);
+
+			source = _mm_unpacklo_epi8(source1, source2);
+			pix = _mm_unpacklo_epi8(source, _mm_setzero_si128());
+			sss = _mm_add_epi32(sss, _mm_madd_epi16(pix, mmk));
+		}
+		for( ; x < n; x++ ) {
+			__m128i pix = mm_cvtepu8_epi32(&in[x * l1 + xx]);
+			__m128i mmk = _mm_set1_epi32(k[x]);
+			sss = _mm_add_epi32(sss, _mm_madd_epi16(pix, mmk));
+		}
+		sss = _mm_srai_epi32(sss, VIPS_INTERPOLATE_SHIFT);
+		sss = _mm_packs_epi32(sss, sss);
+		out[xx] = _mm_cvtsi128_si32(_mm_packus_epi16(sss, sss));
+	}
+}
+#endif
diff --git a/libvips/resample/reduceh.cpp b/libvips/resample/reduceh.cpp
index 1111111..2222222 100644
--- a/libvips/resample/reduceh.cpp
+++ b/libvips/resample/reduceh.cpp
@@ -84,6 +84,10 @@ typedef struct _VipsReduceh {
 	int *matrixi[VIPS_TRANSFORM_SCALE + 1];
 	double *matrixf[VIPS_TRANSFORM_SCALE + 1];
 
+	/* And another set for SIMD.
+	 */
+	short *matrixs[VIPS_TRANSFORM_SCALE + 1];
+	
 	/* Deprecated.
 	 */
 	gboolean centre;
@@ -348,15 +352,22 @@ vips_reduceh_gen( VipsRegion *out_region, void *seq,
 			const int sx = X * VIPS_TRANSFORM_SCALE * 2;
 			const int six = sx & (VIPS_TRANSFORM_SCALE * 2 - 1);
 			const int tx = (six + 1) >> 1;
+			const short *cxs = reduceh->matrixs[tx];
 			const int *cxi = reduceh->matrixi[tx];
 			const double *cxf = reduceh->matrixf[tx];
 
 			switch( in->BandFmt ) {
 			case VIPS_FORMAT_UCHAR:
+#if defined(__AVX2__) || defined(__SSE4_2__)
+				vips_reduce_uchar_simd(
+					q, p,
+					reduceh->n_point, bands, ps, cxs );
+#else
 				reduceh_unsigned_int_tab
 					<unsigned char, UCHAR_MAX>(
 					reduceh,
 					q, p, bands, cxi );
+#endif
 				break;
 
 			case VIPS_FORMAT_CHAR:
@@ -485,17 +496,22 @@ vips_reduceh_build( VipsObject *object )
 			VIPS_ARRAY( object, reduceh->n_point, double ); 
 		reduceh->matrixi[x] = 
 			VIPS_ARRAY( object, reduceh->n_point, int ); 
+		reduceh->matrixs[x] =
+			VIPS_ARRAY( object, reduceh->n_point, short );
 		if( !reduceh->matrixf[x] ||
-			!reduceh->matrixi[x] )
+			!reduceh->matrixi[x] ||
+			!reduceh->matrixs[x] )
 			return( -1 ); 
 
 		vips_reduce_make_mask( reduceh->matrixf[x], 
 			reduceh->kernel, reduceh->hshrink, 
 			(float) x / VIPS_TRANSFORM_SCALE );
 
-		for( int i = 0; i < reduceh->n_point; i++ )
+		for( int i = 0; i < reduceh->n_point; i++ ) {
 			reduceh->matrixi[x][i] = reduceh->matrixf[x][i] * 
 				VIPS_INTERPOLATE_SCALE;
+			reduceh->matrixs[x][i] = (short) reduceh->matrixi[x][i];
+		}
 
 #ifdef DEBUG
 		printf( "vips_reduceh_build: mask %d\n    ", x );
diff --git a/libvips/resample/reducev.cpp b/libvips/resample/reducev.cpp
index 1111111..2222222 100644
--- a/libvips/resample/reducev.cpp
+++ b/libvips/resample/reducev.cpp
@@ -94,6 +94,10 @@ typedef struct _VipsReducev {
 	int *matrixi[VIPS_TRANSFORM_SCALE + 1];
 	double *matrixf[VIPS_TRANSFORM_SCALE + 1];
 
+	/* And another set for SIMD.
+	 */
+	short *matrixs[VIPS_TRANSFORM_SCALE + 1];
+
 	/* Deprecated.
 	 */
 	gboolean centre;
@@ -280,16 +284,23 @@ vips_reducev_gen( VipsRegion *out_region, void *seq,
 		const int sy = Y * VIPS_TRANSFORM_SCALE * 2;
 		const int siy = sy & (VIPS_TRANSFORM_SCALE * 2 - 1);
 		const int ty = (siy + 1) >> 1;
+	  	const short *cys = reducev->matrixs[ty];
 		const int *cyi = reducev->matrixi[ty];
 		const double *cyf = reducev->matrixf[ty];
 		const int lskip = VIPS_REGION_LSKIP( ir );
 
 		switch( in->BandFmt ) {
 		case VIPS_FORMAT_UCHAR:
+#if defined(__AVX2__) || defined(__SSE4_2__)
+			vips_reduce_uchar_simd(
+				q, p,
+				reducev->n_point, ne, lskip, cys );
+#else
 			reducev_unsigned_int_tab
 				<unsigned char, UCHAR_MAX>(
 				reducev,
 				q, p, ne, lskip, cyi );
+#endif
 			break;
 
 		case VIPS_FORMAT_CHAR:
@@ -416,17 +427,22 @@ vips_reducev_build( VipsObject *object )
 			VIPS_ARRAY( object, reducev->n_point, double ); 
 		reducev->matrixi[y] = 
 			VIPS_ARRAY( object, reducev->n_point, int ); 
+		reducev->matrixs[y] =
+			VIPS_ARRAY( object, reducev->n_point, short );
 		if( !reducev->matrixf[y] ||
-			!reducev->matrixi[y] )
+			!reducev->matrixi[y] ||
+			!reducev->matrixs[y] )
 			return( -1 ); 
 
 		vips_reduce_make_mask( reducev->matrixf[y],
 			reducev->kernel, reducev->vshrink, 
 			(float) y / VIPS_TRANSFORM_SCALE ); 
 
-		for( int i = 0; i < reducev->n_point; i++ )
+		for( int i = 0; i < reducev->n_point; i++ ) {
 			reducev->matrixi[y][i] = reducev->matrixf[y][i] *
 				VIPS_INTERPOLATE_SCALE;
+			reducev->matrixs[y][i] = (short) reducev->matrixi[y][i];
+		}
 
 #ifdef DEBUG
 		printf( "vips_reducev_build: mask %d\n    ", y );
